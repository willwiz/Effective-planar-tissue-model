%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%	Discussion												%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discussion}

%-----------------------------------------------------------
%	Model performance
%-----------------------------------------------------------
\subsection{Reproducing soft tissue response for numerical simulations}

	The most fundamental issue with using phenomenological models for soft tissue and organ numerical simulations are that they 1) cannot simulate deformation beyond the range of data used for parameter estimation, and 2) cannot be widely used for tissues other than the ones they are specifically formulated for. Without being able to fully reproduce the response of micro-models, the resulting response may become inconsistent with the mechanisms of these micro-models, impacting their ability to simulate soft tissue responses, particular when modeling time-dependent processes. In the present work we found that using $\Psi_{eff}$ (Eqn. \ref{eqn:finalexponentialmodelformscaled}) along with optimally selected loading paths reconciles this issue. $\Psi_{eff}$ demonstrates much better capabilities at fitting the mechanical response of soft tissues in general. Admittedly, this may not be especially important for simulations of soft tissues in the normal physiological range as most models can fit the response of tissues if the range of deformation is small, as demonstrated with the generalized Fung model. However, for simulating abnormal conditions such as those that will drastically alters the deformation of the tissue, then using $\Psi_{eff}$ will be much more accurate. 
    
    The second and equally important part is the need for optimal data to determine the model parameters. Admittedly, the amount of data needed is not necessarily extensive. For example, we have shown that just three carefully selected loading paths can greatly improve the predictive capability of $\Psi_{eff}$ over the entire range of deformations. However, when the loading paths are selected poorly, $\Psi_{eff}$ still has some issue when predicting protocol beyond the range used to fit the model. Examples of this are only using a single protocol under equi-biaxial stress (Appendix \ref{sec:otherresults}, Fig. \ref{fig:effequifit}D), or only using protocols in the post-pre-strain range (Fig. \ref{fig:effphypred}). Mechanisms are still the major factor limiting the predictive capability in these cases. However, as the intended role of $\Psi_{eff}$ is to homogenize the response of mechanisms-based micro-models, the loading paths can be simulated by choice, thus should not be a major factor affecting $\Psi_{eff}$ in numerical simulations. 
    
     As we have shown, $\Psi_{eff}$ is able to handle a wide range of soft tissue behavior with no change in model form. This greatly simplifies the need of implementing a different constitutive models for every tissue type, especially when the Jacobian or the elasticity tensor must be implemented separately for computational efficiency, which can be quite complex, i.e. in ABAQUS UMAT. $\Psi_{eff}$ alone is capable of fully reproducing their mechanical response for simulations without significant loss in accuracy. Thus, the use of effective constitutive models can greatly facilitate in not only the computation speed of numerical simulations, but also the speed of implementing constitutive models of different soft tissue for simulations. In these cases, only the parameters of $\Psi_{eff}$ and organ geometry needs to be changed. $\Psi_{eff}$ is smooth, easily differentiable, and easy to implement. With optimal loading path and model scaling, the process of converting micro-model response to $\Psi_{eff}$ (Eqn. \ref{eqn:finalexponentialmodelformscaled}) should take not more than a few seconds, while saving a significant amount of time during numerical simulations. 
     
     On the other hand, micro-models such as the meso-scale structural models are also very useful for reproducing the response of tissue to which the the full microstructure are known. This avoids the need for extensive mechanical data and parameter estimation, saving a time consuming step for evaluating different material designs. Some structural and geometry information may also be measurable \textit{in vivo} due to advances in techniques such as 3D ultrasound \cite{steiner_diagnostic_1994, yang_3d_2008, fenster_3_1996} and DT-MRI \cite{basser_vivo_2000, basser_microstructural_2011}, and can be directly incorporated into meso-scale structural models. However, these techniques do not yet offer sufficient information to directly determine the mechanical properties of tissues. As such, micro-models are still a necessary and important part of any predictive simulation. Not surprisingly, even most traditional invariant based models, such as the Holzapfel-Gasser-Ogden model \cite{holzapfel_new_2000}, are being extended to incorporate the microstructures of the tissue \cite{holzapfel_modelling_2015}. 
    
    


\subsection{Application for the effective constitutive model}
%-------	growth and remodeling	-------%
    
    One application of effective constitutive models is for simulating time-dependent processes, such as growth and remodeling. Growth and remodeling has been a long-time interest of the biomechanics community, and has important role in predictive simulations. Theories for growth and remodeling have been well studied, from Rodriguez in 1994 to Lanir and others in the current time \cite{lanir_mechanistic_2014, gleason_mixture_2004, rodriguez_stress_1994, humphrey_constrained_2002, cowin_tissue_2004, taber_biomechanics_1995}. The general theories for growth and remodeling involves the changes in the reference configurations of the materials and a constrained mixture model involving the combined response of old original materials and new generated materials. The new and old materials are separated into many different parts each with its own material parameters and referential configuration. This again multiplies the computational cost of the material models and the summation of many individual responses can significantly reduce numerical precision. Here homogenization using $\Psi_{eff}$ (Eqn. \ref{eqn:finalexponentialmodelformscaled}) can be useful. 
    

%-------	inverse modeling	-------%
    Another important application is for inverse modeling, which is important for patient specific modeling. Outside of \textit{in vitro} studies, performing the experiments necessary to determine the mechanical response of soft tissues is extremely difficult. Here, inverse modeling approaches are a solution to this problem \cite{lee_inverse_2014, aggarwal_inverse_2015, aggarwal_patient_2013, kim_inverse_2009, liu_inverse_2013}. In inverse modeling, the model parameters and the errors between the simulated and measured strains are simultaneously optimized. However, the available data that can be obtained \textit{in vivo} is limited, and is not always sufficient to accurately determine the model parameters. In these cases, the tissue microstructure can be used along with meso- and multi-scale models to narrow down the range of possible parameters. However, this multiplies the already hefty costs of the these constitutive models, which is complicated by the fact that limited time is available to acquire these model parameters. Here, the approach we proposed (Fig. \ref{fig:simulationframework}B) can be used to reduce computational cost.

%-----------------------------------------------------------
%	Model covariance
%-----------------------------------------------------------
% \subsection{Alternative model forms}

% % 	The standard invariants and pseudo-invariants (Section \ref{sec:invariants}), is not suitable for ours goals for an effective constitutive model. It is more suitable for specific tissue types and is hard to generalize. In some specific cases, such as choosing $I_4 = \vec{M}\cdot\mathbf{C}\vec{M}$, $I_5 = \vec{P}\cdot\mathbf{C}\vec{P}$, and $I_8 = \vec{M}\cdot\mathbf{C}\vec{P}$, $\vec{P}$ orthogonal to $\vec{M}$, you can construct the exact same effective constitutive model, since then $E_m = 1/2(I_4 - 1)$, $E_n = 1/2(I_5 - 1)$, and $E_\phi = 1/2(I_8)$. However, there isn't any point of using invariants if they are restricted to have the same value as the components of strain tensors, this only makes the mathematics more difficult to follow. Using other invariants that are not just just the right Cauchy strain components, can more specifically describe the tissue tissue function. One example is the dual crossing fiber families in arterial tissues. However, this loss in generality is exactly what we want to avoid. What we want is a constitutive model that can fully reproduce the response of a wide range of soft tissue responses. 
    
    
% %     To be fully general, the choice of invariants used in the model really can't be specific to any mechanism or structure. In the end, the 'smallest and complete set of invariants' that can describe any deformation is the strain tensor components themselves. The choices for the strain tensors and conjugate stresses are many, but they are also very similar. The Hencky strains produces the best parameter covariance for constitutive modeling, but this difference is simply not enough to justify using it in place of other strain basis. Likely, there isn't a significant advantage for any specific strain basis in this area. $\mathbf{E}$ is the most convenient for constitutive modeling with the simplest forms for stresses and elasticity tensor (Appendix \ref{sec:elasticitytensor}), thus stands out as the most convenience. 
    

% 	Our first choice for $\Psi_{eff}$ (Eqn. \ref{eqn:finalexponentialmodelformscaled}) is the polynomial series type (Eqn. \ref{eqn:polynomialmodelform}). It has a lot more flexibility for reproducing just about any response. But the number of parameter is too many, and enforcing convexity on the resulting response is too difficult in terms of the number of constraints needed and computational cost added to the model, and parameter estimation. Optimization problems normally taking only 10-20 iterations to converge without constraints, took 200,000 iterations and still did not converge with the constraints added. This process was only stopped after 6 hours by the max iteration value. In such conditions, polynomial series type is clearly not a viable choice. However, we should note that the Hencky strains are extremely beneficial to polynomial series type models, which significantly reduces the parameter correlations (Appendix \ref{sec:parametercorrelation}, Fig. \ref{fig:gvsecorrelationpoly}). Most of the benefits are for the coupling terms in the higher order polynomials. These benefits are greatly reduced for the lower order terms such as those in $\Psi_{eff}$ Although the polynomial series and separated exponential types have lower parameter covariance by separating the individual terms, more coupling terms are needed to fit soft tissue responses, actually increasing the overall covariance of the model. Thus, the disadvantage in parameter covariance in the exponential Q type models is actually less significant overall for parameter estimation. Also, with the model scaling method presented (Section \ref{sec:modelscaling}), parameter covariance does not seem to be an issue for $\Psi_{eff}$. 


%-----------------------------------------------------------
%	Convexity
%-----------------------------------------------------------
\subsection{Convexity}
	
    We did not find any difficulties with enforcing the convexity of $\Psi_{eff}$ (Eqn. \ref{eqn:finalexponentialmodelformscaled}) during parameter estimation. In fact, no constraints were necessary in most cases. Even in the worst scenarios, only a few constraints are required (Eqn. \ref{eqn:effmodelconstraints}). The biggest difficulties with enforcing convexity and ellipticity are the coupling terms such as $E_m^3E_n$ and $E_mE_n^3$. Polynomial series or separated exponential types require many more coupling terms in comparison to $\Psi_{eff}$. Our preliminary testing shows that polynomial model form requires at least 27 terms to fit existing data, 21 of the 27 terms are coupling terms. The resulting constraints are both complex and difficult to enforce. Enforcing convexity and ellipticity on the boundary or any specific points do not guarantee convexity over the entire range. Thus, convexity need to be enforced at separate points within the domain or by integration. This is not only a significant increase in computational costs, as the computational cost of enforcing the constraints vastly exceeds that of the model itself, but also significantly impacts convergence during optimization. The constraint functions are not convex themselves by any means, increasing the number of iterations needed for optimization by several magnitudes more than necessary. In many cases, parameter estimation took 200,000 iterations without convergence after enforcing the constraints, taking over 6 hours by the max iteration value, which is comparable to meso-scale structural approaches with interaction terms \cite{zhang_modeling_2017}(30 min - 4 hours). This makes constrained optimization often intractable to implement, especially in comparison to $\Psi_{eff}$ (Eqn. \ref{eqn:finalexponentialmodelformscaled}) which only takes 5-10 seconds. Thus, the form of $\Psi_{eff}$ proposed is clearly the best choice. 
    

%-----------------------------------------------------------
%	Convergence
%-----------------------------------------------------------
\subsection{Model scaling method and its applications}
    
    Although not introduced as such, the model scaling method, or a similar technique to this, was very actually briefly described by Fung \textit{et al.} in their original work on the mathematical modeling of arteries \cite{fung_pseudoelasticity_1979}. The paper introduced the strain energy density function as 
%==========================================================%
%-------------------	begin EQUATION 	-------------------%
\begin{equation}\label{eqn:fungarterymodel}
\rho_0 W^{(2)} = \frac{C^\prime}{2}\operatorname{exp}\left[\alpha_1 \left(E_{\theta\theta}^2 - E_{\theta\theta}^{*2} \right) + \alpha_2 \left(E_{zz}^2 - E_{zz}^{*2} \right) + \alpha_4 \left(E_{\theta\theta}E_{zz} - E_{\theta\theta}^*E_{zz}^* \right) \right]
\end{equation}
%-------------------	 end EQUATION 	-------------------%
%==========================================================%    
in equation 2 of the said work ($C$ is changed to $C^\prime$ to consistency in notation with the present work). $E_{\theta\theta}^*$ and $E_{zz}^*$ are introduced as strains corresponding to some fixed stresses of $S_{\theta\theta}^*$ and $S_{zz}^*$, usually taken in the physiologic range. Similarly, this "scaling" can be absorbed into the parameter $C^\prime$ like in the present work. This idea was not greatly expanded upon, but \textit{Fung et al.} notes that:
\begin{quotation}
"But in practice it is very helpful to introduce $E_{\theta\theta}^*$ and $E_{zz}^*$. Not only are the values corresponding to $S_{\theta\theta}^*$ and $S_{zz}^*$ very important information, but also their use makes the constants [$C^\prime$], $\alpha_1$, $\alpha_2$, and $\alpha_4$ much more stable for each set of specimen." \cite{fung_pseudoelasticity_1979}
\end{quotation} 
and that 
\begin{quotation}
"[$E_{\theta\theta}^*$ and $E_{zz}^*$] are indexes of compliance of the vessel. Using $E_{\theta\theta}^*$ and $E_{zz}^*$, the variations of the constants $C$, $\alpha_1$, $\alpha_2$, and $\alpha_4$, which determines the shape of the stress-strain curve, are greatly reduced. The assignment of $S_{\theta\theta}^*$ and $S_{zz}^*$ is arbitrary, but hopefully standard values will be adopted by the biomechanics community." \cite{fung_pseudoelasticity_1979}
\end{quotation}

	In truth, we did not find that the model scaling method necessarily makes $\alpha_1$, $\alpha_2$, and $\alpha_4$ more consistent, but rather that they are exactly the same values with or without this method, assuming parameter estimation was not trapped in some local minimum. The model scaling method does make reaching the values of these parameter more consistent. The biggest benefit remains the significant improvement in the correlation between the parameters $C^\prime$ and $\alpha_1$, $\alpha_2$, and $\alpha_4$, improving the topology of the objective function surface during parameter estimation. It also imparts some physical meaning to the value of $C^\prime$, or for $A_s$ and $c_0^\prime$ in present work. For Fung \textit{et al.}, this is some arbitrary physiologic stresses, for us, this is exactly 'maximum' (with respect to the objective function) value of strain energy within the data used for parameter estimation. This does bestow some consistency to the value of $C^\prime$, as it is exactly the total strain energy density at the stresses of $S_{\theta\theta}^*$ and $S_{zz}^*$, which will likely be similar between specimens taken from the same arteries from health subjects. However, the choice of $E_{\theta\theta}^*$ and $E_{zz}^*$, or $E_m^\mathrm{max}$, $E_n^\mathrm{max}$, and $E_\phi^\mathrm{max}$ for $\Psi_{eff}$ (Eqn. \ref{eqn:finalexponentialmodelformscaled}), should not be arbitrary. The model scaling method works due to altering the functional effect of $c_0$ and $b_i$, or $C$ and $\alpha$. $E_m^\mathrm{max}$, $E_n^\mathrm{max}$, and $E_\phi^\mathrm{max}$ should be chosen deliberately so that area under the constitutive model, based on the objective function, remains approximately the same, thus decoupling changes in modulus and changes in curvature from the exponential parameters. 


	Perhaps, the biggest advantage of the model scaling method is that it is applicable to nearly any constitutive model with an exponential function, such as models like the Holzapfel-Gasser-Ogden, Humphrey, Vito, or even the meso-scale structural model with simplified ensemble response such as in Fan and Sacks \cite{fan_simulation_2014a}, Lee \textit{et al.}\cite{lee_effects_2015}, and Aggarwal and Sacks \cite{aggarwal_inverse_2015}. Even polynomial model forms with a power law, $\Psi=A\epsilon^B$, such as the generalized Ogden model, or the elastin model for the mitral valve in Zhang et al. \cite{zhang_meso_2016} can see benefits from the model scaling method. In this case, the scaling term becomes $A = \bar{A} e^{-B \log(\epsilon_{max})}$. In summary, this model scaling method should have significantly implications in improving the speed and consistency of parameter estimation for any model with an exponential like form.
    
    
	
    
%-----------------------------------------------------------
%	Convergence
%-----------------------------------------------------------
\subsection{Convergence rate}

	Typically, we find that parameter estimation converges after 40-60 iterations, although more stringent tolerance may require more iterations for additional digits of precision. We did not observe significant improvements in the rate of convergence in the best-case scenarios, but we also did not observe scenarios which significantly increases the iteration required based on the initial guess like the unscaled traditional forms. We note that the model scaling method does not improve the correlation between the exponent parameters $b_1-b_{13}$ in $Q$, which is a function of the choice of invariants and the terms picked. With that being said, the correlation between the parameters of $Q$ is much better than the correlation between the exponents $b_1-b_{13}$ and modulus $c_0$ (Fig. \ref{fig:gvsecorrelation} and Appendix \ref{sec:parametercorrelation} Table \ref{tb:correlationE} \& \ref{tb:correlationG} vs. Table \ref{tb:ABcorrelation}), it is difficult to further improve the parameter correlation of $Q$ without changing the form of the model. However, for our purpose, this is already sufficient. 

%-----------------------------------------------------------
%	Optimal
%-----------------------------------------------------------
\subsection{Optimal \textit{in silico} loading paths}

	The limitation on predicting outside of the loading paths used for parameter estimation can be somewhat remedied by densely sampling the response of the micro-model over a larger range of deformations. However, this is not entirely ideal for computational speed during parameter estimation, and sampling data points for parameter estimation is not a trivial task itself. Points with high stresses tends to weight heavily during parameter estimation, proper care need to be taken to capture both the high stress and low stress response. Given that the number of data points scales cubically with the separation between data points, this approach is still limited. We will test if using $\Psi_{eff}$ (Eqn. \ref{eqn:finalexponentialmodelformscaled}) along with the use of optimal loading paths can be the solution to this problem. 

	The optimal \textit{in silico} loading paths for parameter estimation and mechanical testing is perhaps very intuitive. The two key factors that should always be consider when sampling data or performing experimental testing are 1) span the as much of the range of deformation as possible and 2) the equibiaxial stress loading path is extremely important. Our optimal design simulations for the loading paths support these views. The equibiaxial stress loading path is always the one shown in figures for most paper, as it gives most intuitively understandable information on the mechanical properties of the tissue. It gives insights into the general form, anisotropy and stiffness of the material at a glance, and is not surprisingly also the best loading path for parameter estimation. Spanning the domain of the possible deformations provides more information for parameter estimation also as expected. However, it is surprising just how little the equibiaxial stress loading path can provide alone. The difference in magnitude between the D-optimality values for one vs. two loading paths is almost 20. The equibiaxial stress alone simply is not enough for accurate parameter estimation of the full response of soft tissues when using $\Psi_{eff}$ (Eqn. \ref{eqn:finalexponentialmodelformscaled}). However, with the addition of one or two more protocols, even if they are along a similar loading paths can significantly improve the predictive capabilities of $\Psi_{eff}$. Reproducing the mechanical response of soft tissues from only fitting the equibiaxial response in figures from papers is unlikely to be sufficient. However, this may be partially overcome by meso-scale structural approaches, given the information on the microstructure of the tissue.  
    
    Having said this, our investigation of optimal loading paths only restricted to constant strain ratios or constant stress ratios. In reality, there are many ways to define loading paths, some can be quite creative. We do not deny the possibility of other forms of loading paths that are more optimal than using stress ratios, but a fully exhaustive search is not an easy problem to tackle and program for optimization. In our search, we restricted the optimization to only the same family of loading paths, defined by only one constant, the ratio of stretch. Even so, the parts of the process is manual, such as increasing the total number of loading paths. Increasing the total number of loading paths was extremely time consuming for most algorithms due to exponentially increasing computational cost (section \ref{sec:optimaldesign}). However, three, or at most five protocols are already sufficient. 
    
    We did test some alternative loading paths, such as Fung \textit{et al.}'s post pre-strain loading paths \cite{fung_pseudoelasticity_1979}. They cover much of the physiological range, but are insufficient for parameter estimation. Increasing the number of loading paths in this case, has minor improvements, but pales in comparison to just picking better types of loading paths. The poor predictive capabilities for the low stress region can have significant impacts on underestimating the mechanical properties of matrix and elastin, and their properties can be important to the functions of micro-models. The mechanical properties of the matrix for example, having significant implications for simulating the process of permanent set in exogenously cross-linked soft tissues \cite{zhang_modeling_2017}. Failing to properly reproduce this response, can affect the predictive capabilities of the associated micro-models, causing the whole framework of using $\Psi_{eff}$ to facilitate numerical simulations (Fig. \ref{fig:simulationframework}B) to fall apart. 
    
    
    
%-----------------------------------------------------------
%	Simulation
%-----------------------------------------------------------
% \subsection{Numerical simulation}
	

 








